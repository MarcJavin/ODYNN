{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plotting some traces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import data\n",
    "import pylab as plt\n",
    "import torch\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "sensors = ['ALNL', 'ALNR', 'ASKL', 'ASKR', 'BAGL', 'OLQDL', 'OLQDR', 'OLQVL', 'OLQVR', 'PHAR']\n",
    "\n",
    "plt.figure(figsize=(30,8))\n",
    "traces = data.get_data()#[sensors + ['AVAR']]\n",
    "traces.index = np.arange(len(traces))\n",
    "dvdt = data.get_deriv()\n",
    "print(traces.shape, dvdt.shape)\n",
    "\n",
    "avaup = traces['AVAL']>0.6\n",
    "avarising = dvdt['AVAR'] > 0.02\n",
    "avarise = avarising.astype(int).diff() > 0\n",
    "weights = avaup*2 + 1\n",
    "\n",
    "# sns.heatmap(traces.corr(), cmap='bwr', vmin=-1, vmax=1, annot=True)\n",
    "# plt.plot(traces['ALNR'].values)\n",
    "# plt.plot((traces['OLQDR'].values - traces['ALNR'].values) * 5)\n",
    "# plt.plot((traces['BAGL'].values) * 5)\n",
    "# plt.plot(traces['ASKR'].values )\n",
    "# for i in range(0,3500,150):\n",
    "#     plt.axvline(i, color='k')\n",
    "# plt.plot((traces['SMDDR'].values) * 2)\n",
    "# plt.plot((traces['OLQVR'].values) * 3)\n",
    "plt.plot(traces['VA01'], 'r')\n",
    "plt.plot(traces['AVEL'])\n",
    "plt.plot(traces['AVER'])\n",
    "plt.plot(traces['AVAL'])\n",
    "plt.plot(avarising)\n",
    "plt.plot( avarise )\n",
    "# plt.plot(dvdt['AVAL']>0.02)\n",
    "# plt.plot(traces['PHAR']*3)\n",
    "\n",
    "# plt.plot(weights)\n",
    "\n",
    "cor = traces[sensors + ['AVAL']].corr()\n",
    "# sns.heatmap(cor, cmap='seismic', vmin=-1, vmax=1, annot=True)\n",
    "\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "\n",
    "risewhy = pd.DataFrame(0., index=np.arange(20), columns=traces.columns)\n",
    "for i in np.argwhere(avarise.values > 0.5):\n",
    "    i = i[0]\n",
    "    risewhy = pd.DataFrame(risewhy.values + traces.iloc[i-10:i+10, :])\n",
    "risewhy /= avarise.sum()\n",
    "    \n",
    "# plt.figure(figsize=(3,25))\n",
    "# for i,c in enumerate(risewhy.columns):\n",
    "#     plt.plot(risewhy[c] + 0.5*i)\n",
    "# plt.axvline(3203, color='k', linestyle='--')\n",
    "# plt.show()\n",
    "\n",
    "# plt.plot(traces['VA01'])\n",
    "# plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression, LogisticRegression\n",
    "from sklearn.model_selection import KFold\n",
    "import pandas as pd\n",
    "from copy import copy\n",
    "import itertools\n",
    "import numpy as np\n",
    "\n",
    "def list_of_combs(arr):\n",
    "    \"\"\"returns a list of all subsets of a list\"\"\"\n",
    "    \n",
    "    combs = []\n",
    "    for i in range(0, len(arr)+1):\n",
    "        listing = [list(x) for x in itertools.combinations(arr, i)]\n",
    "        combs.extend(listing)\n",
    "    return combs\n",
    "\n",
    "def predict(pred=sensors, x=None, yi='AVAR', y=None, w=None, deriv=False):\n",
    "\n",
    "#     for preds in list_of_combs(pred)[1:]:\n",
    "    \n",
    "    preds = pred\n",
    "    df = data.get_data()\n",
    "    df.index = np.arange(len(df))\n",
    "    X = df[preds]\n",
    "    names = preds\n",
    "    if deriv:\n",
    "        X = pd.concat([X, dvdt[preds]], axis=1)\n",
    "        X.fillna(0, inplace=True)\n",
    "        names = names + ['d%s/dt'%n for n in preds]\n",
    "    if y is None:\n",
    "        y = df[yi]\n",
    "\n",
    "\n",
    "    model = LinearRegression(normalize = True)\n",
    "#     model = LogisticRegression(tol = 1e-7)\n",
    "    model.fit(X, y, w)\n",
    "#     print(model.coef_.shape, len(names))\n",
    "    print(pd.DataFrame(model.coef_[None], columns=names))\n",
    "    score = model.score(X, y)\n",
    "\n",
    "    plt.figure(figsize=(15,5))\n",
    "    plt.plot(np.arange(len(y)), y, 'r')\n",
    "#   out = model.predict_proba(X)[:,1]\n",
    "    out = model.predict(X)\n",
    "    plt.plot(out, 'k')\n",
    "#     plt.axhline(0.5, color='k', linestyle='--')\n",
    "#     plt.plot(model.predict(X))\n",
    "    print(model.predict(X).sum())\n",
    "    plt.show()\n",
    "    return probs\n",
    "    \n",
    "sens = sensors.copy()\n",
    "sens.remove('OLQDL')\n",
    "sens.remove('OLQVL')\n",
    "sens.remove('OLQDR')\n",
    "# sens.remove('OLQVR')\n",
    "# predict(pred=sens, yi='AVAR')\n",
    "p = predict(pred=['AVAL', 'AVBL', 'AVEL'], yi='ALNL', deriv=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_curve\n",
    "\n",
    "roc = roc_curve(avaup, p, sample_weight=weights)\n",
    "plt.plot(roc[0], roc[1])\n",
    "plt.xlabel('False positive rate')\n",
    "plt.ylabel('True positive rate')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# LSTM for predicting AVA up from sensory neurons traces\n",
    "import numpy\n",
    "import matplotlib.pyplot as plt\n",
    "from pandas import read_csv\n",
    "import math\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LSTM\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import mean_squared_error, log_loss\n",
    "from keras.utils import to_categorical\n",
    "# convert an array of values into a dataset matrix\n",
    "\n",
    "idx_tr = []\n",
    "idx_te = []\n",
    "\n",
    "class Test(Callback):\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        if epoch%10 != 0:\n",
    "            return\n",
    "        # make predictions\n",
    "        trainPredict = model.predict(trainX)\n",
    "        testPredict = model.predict(testX)\n",
    "\n",
    "        # plot baseline and predictions\n",
    "        plt.figure(figsize=(12,3))\n",
    "        plt.plot(y[:,-1], 'g')\n",
    "        plt.plot(idx_tr, trainPredict[:,-1], 'ko', ms=1)\n",
    "        plt.plot(idx_te, testPredict[:,-1], 'ro', ms=1)\n",
    "        plt.show()\n",
    "        print('test loss: ', log_loss(testY, testPredict))\n",
    "\n",
    "def create_dataset(X, y, look_back=10, offset=0):\n",
    "    dataX, dataY, idx = [], [], []\n",
    "    for i in range(len(y)-look_back-1):\n",
    "        # sensors from prev timesteps\n",
    "#         if avaup[offset+i+look_back-1]:\n",
    "#             continue\n",
    "        a = X[i:(i+look_back)]\n",
    "        dataX.append(a)\n",
    "        # AVA up at t+1\n",
    "        dataY.append(y[i + look_back])\n",
    "        idx.append(offset + i + look_back)\n",
    "    return numpy.array(dataX), numpy.array(dataY), idx\n",
    "# fix random seed for reproducibility\n",
    "numpy.random.seed(7)\n",
    "# normalize the dataset\n",
    "X = data.get_data()[['ASKL', 'ASKR']].values\n",
    "# scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "# X = scaler.fit_transform(X)\n",
    "print(X.shape)\n",
    "\n",
    "# y = data.get_data()[['AVAR']].values\n",
    "\n",
    "y = avarise.values\n",
    "y = to_categorical(y)\n",
    "print(y.shape)\n",
    "\n",
    "# split into train and test sets\n",
    "train_size = int(len(y) * 0.7)\n",
    "test_size = len(y) - train_size\n",
    "xtr, ytr, xte, yte = X[-train_size:,:], y[-train_size:], X[:-train_size,:], y[:-train_size]\n",
    "# reshape into X=t and Y=t+1\n",
    "look_back = 150\n",
    "trainX, trainY, idx_tr = create_dataset(xtr, ytr, look_back, offset = test_size)\n",
    "testX, testY, idx_te = create_dataset(xte, yte, look_back)\n",
    "# reshape input to be [samples, time steps, features] already done\n",
    "# create and fit the LSTM network\n",
    "model = Sequential()\n",
    "model.add(LSTM(10, return_sequences=True, input_shape=(trainX.shape[1], trainX.shape[2])))\n",
    "model.add(LSTM(5))\n",
    "model.add(Dense(y.shape[-1], activation='softmax'))\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "test = Test()\n",
    "callbacks_list = [test]\n",
    "# fit the model\n",
    "print(trainX.shape)\n",
    "model.fit(trainX, trainY, epochs=1000, batch_size=64, callbacks=callbacks_list, verbose=2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy.random import rand\n",
    "\n",
    "print(trainX.shape, testY.shape)\n",
    "X = testX[:look_back,0,:]\n",
    "print(X.shape)\n",
    "res = X\n",
    "\n",
    "n_pred = 1300\n",
    "for i in range(n_pred):\n",
    "    X = np.array(res[-look_back:])[None]\n",
    "    x = model.predict(X)\n",
    "    nxt = testX[look_back+i,0,:]\n",
    "    nxt[-1] = x\n",
    "    res = np.concatenate((res, nxt[None]))\n",
    "print(res.shape)\n",
    "plt.plot(res[:,-1], 'r')\n",
    "plt.plot(np.arange(look_back, look_back+n_pred), testY[:n_pred], color='k', linestyle='--')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Autoencoder\"\"\"\n",
    "\n",
    "# LSTM for predicting AVA up from sensory neurons traces\n",
    "import numpy\n",
    "import matplotlib.pyplot as plt\n",
    "from pandas import read_csv\n",
    "import math\n",
    "from tensorflow import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LSTM\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import mean_squared_error, log_loss\n",
    "from keras.utils import to_categorical\n",
    "from keras.callbacks import Callback\n",
    "# convert an array of values into a dataset matrix\n",
    "\n",
    "idx_tr = []\n",
    "idx_te = []\n",
    "\n",
    "class Test(Callback):\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        if epoch%10 != 0:\n",
    "            return\n",
    "        # make predictions\n",
    "        trainPredict = model.predict(trainX)\n",
    "        testPredict = model.predict(testX)\n",
    "\n",
    "        # plot baseline and predictions\n",
    "        plt.figure(figsize=(12,3))\n",
    "        plt.plot(X[:,-1], 'g')\n",
    "        plt.plot(trainPredict[:,-1], 'ko', ms=1)\n",
    "        plt.plot(testPredict[:,-1], 'ro', ms=1)\n",
    "        plt.show()\n",
    "        print('test loss: ', log_loss(testY, testPredict))\n",
    "\n",
    "def create_dataset(X, look_back=10):\n",
    "    dataX = []\n",
    "    for i in range(len(y)-look_back-1):\n",
    "        a = X[i:(i+look_back)]\n",
    "        dataX.append(a)\n",
    "        \n",
    "    return numpy.array(dataX)\n",
    "# fix random seed for reproducibility\n",
    "numpy.random.seed(7)\n",
    "# normalize the dataset\n",
    "X = data.get_data().values\n",
    "scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "X = scaler.fit_transform(X)\n",
    "print(X.shape)\n",
    "\n",
    "# y = data.get_data()[['AVAR']].values\n",
    "\n",
    "y = X \n",
    "print(y.shape)\n",
    "\n",
    "# split into train and test sets\n",
    "train_size = int(len(y) * 0.7)\n",
    "test_size = len(y) - train_size\n",
    "xtr, xte = X[-train_size:,:], X[:-train_size,:]\n",
    "# reshape into X=t and Y=t+1\n",
    "look_back = 150\n",
    "trainX = create_dataset(xtr, look_back)\n",
    "testX = create_dataset(xte, look_back)\n",
    "# reshape input to be [samples, time steps, features] already done\n",
    "# create and fit the LSTM network\n",
    "model = Sequential()\n",
    "model.add(LSTM(10, return_sequences=True, input_shape=(trainX.shape[1], trainX.shape[2])))\n",
    "model.add(LSTM(5))\n",
    "model.add(LSTM(10))\n",
    "model.add(LSTM(trainX.shape[1], activation='softmax'))\n",
    "model.compile(loss='mean_squared_error', optimizer='adam', metrics=['mean_squared_error'])\n",
    "test = Test()\n",
    "callbacks_list = [test]\n",
    "# fit the model\n",
    "print(trainX.shape)\n",
    "model.fit(trainX, trainX, epochs=1000, batch_size=64, callbacks=callbacks_list, verbose=2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
